{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rfq-zan/CNN_GTSRB_Recognition/blob/main/TrafficSignClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drrDu3QgnwRZ"
      },
      "outputs": [],
      "source": [
        "!git clone https://bitbucket.org/jadslim/german-traffic-signs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UX-4Rz1od92"
      },
      "outputs": [],
      "source": [
        "!ls german-traffic-signs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mtyTtgxkl8x"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import random\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gNUycnS19c3"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04WEROGAns5B"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moKrVFYqoz4p"
      },
      "outputs": [],
      "source": [
        "with open('german-traffic-signs/train.p', 'rb') as f:\n",
        "  train_data = pickle.load(f)\n",
        "with open('german-traffic-signs/valid.p', 'rb') as f:\n",
        "  val_data = pickle.load(f)\n",
        "with open('german-traffic-signs/test.p', 'rb') as f:\n",
        "  test_data = pickle.load(f)\n",
        "\n",
        "print(type(train_data))\n",
        "X_train, y_train = train_data['features'], train_data['labels']\n",
        "X_val, y_val = val_data['features'], val_data['labels']\n",
        "X_test, y_test = test_data['features'], test_data['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_w9LxHuqD0v"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpC9OvE8qxN_"
      },
      "outputs": [],
      "source": [
        "assert(X_train.shape[0] == y_train.shape[0]), \"The no of images is not equal to the no of labels\"\n",
        "assert(X_val.shape[0] == y_val.shape[0]), \"The no of images is not equal to the no of labels\"\n",
        "assert(X_test.shape[0] == y_test.shape[0]), \"The no of images is not equal to the no of labels\"\n",
        "assert(X_train.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3\"\n",
        "assert(X_val.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3\"\n",
        "assert(X_test.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNRovqF6r68v"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('german-traffic-signs/signnames.csv')\n",
        "\n",
        "num_of_samples=[]\n",
        "\n",
        "cols = 5\n",
        "num_classes = 43\n",
        "\n",
        "fig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5,50))\n",
        "fig.tight_layout()\n",
        "\n",
        "for i in range(cols):\n",
        "  for j, row in data.iterrows():\n",
        "    x_selected = X_train[y_train == j]\n",
        "    axs[j][i].imshow(x_selected[random.randint(0,(len(x_selected) - 1)), :, :], cmap=plt.get_cmap('gray'))\n",
        "    axs[j][i].axis(\"off\")\n",
        "    if i == 2:\n",
        "      axs[j][i].set_title(str(j) + \" - \" + row[\"SignName\"])\n",
        "      num_of_samples.append(len(x_selected))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R84oU7gwtzU8"
      },
      "outputs": [],
      "source": [
        "print(num_of_samples)\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.bar(range(0, num_classes), num_of_samples)\n",
        "plt.title(\"Distribution of the train dataset\")\n",
        "plt.xlabel(\"Class number\")\n",
        "plt.ylabel(\"Number of images\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZumaSUvu8mQ"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X_train[1000])\n",
        "plt.axis(\"off\")\n",
        "print(X_train[1000].shape)\n",
        "print(y_train[1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFJUg4j-vYDa"
      },
      "outputs": [],
      "source": [
        "def grayscale(img):\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  return img\n",
        "\n",
        "img = grayscale(X_train[1000])\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmGR7UcYwWpW"
      },
      "outputs": [],
      "source": [
        "def equalize(img):\n",
        "  img = cv2.equalizeHist(img)\n",
        "  return img\n",
        "\n",
        "img = equalize(img)\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZXRiXvzxW7i"
      },
      "outputs": [],
      "source": [
        "def preprocessing(img):\n",
        "  img = grayscale(img)\n",
        "  img = equalize(img)\n",
        "  img = img/255\n",
        "  return img\n",
        "\n",
        "X_train = np.array(list(map(preprocessing, X_train)))\n",
        "X_val = np.array(list(map(preprocessing, X_val)))\n",
        "X_test = np.array(list(map(preprocessing, X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_gVhP0DyYeX"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X_train[random.randint(0, len(X_train) - 1)])\n",
        "plt.axis(\"off\")\n",
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z90Lo-_ByvSJ"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(34799, 32, 32, 1)\n",
        "X_test = X_test.reshape(12630, 32, 32, 1)\n",
        "X_val = X_val.reshape(4410, 32, 32, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGURV-_s2gIF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuuKUIRyt2UW"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            zoom_range=0.2,\n",
        "                            shear_range=0.1,\n",
        "                            rotation_range=10.)\n",
        "datagen.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7GbvbievV3T"
      },
      "outputs": [],
      "source": [
        "batches = datagen.flow(X_train, y_train, batch_size=20)\n",
        "X_batch, y_batch = next(batches)\n",
        "\n",
        "fig, axs = plt.subplots(1, 15, figsize = (20, 5))\n",
        "fig.tight_layout()\n",
        "\n",
        "for i in range(15):\n",
        "  axs[i].imshow(X_batch[i].reshape(32, 32))\n",
        "  axs[i].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWS7ZLi22nNJ"
      },
      "outputs": [],
      "source": [
        "print(X_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CApNm1J0zQuW"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwe1YDNUzX1k"
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train, 43)\n",
        "y_test = to_categorical(y_test, 43)\n",
        "y_val = to_categorical(y_val, 43)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls6guhEUzkCD"
      },
      "outputs": [],
      "source": [
        "def leNet_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(60,(5, 5), input_shape=(32, 32, 1), activation='relu'))\n",
        "  model.add(Conv2D(60,(5, 5), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(30, (3, 3), activation='relu'))\n",
        "  model.add(Conv2D(30, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(500, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(43, activation='softmax'))\n",
        "  #Compile model\n",
        "  model.compile(Adam(learning_rate=0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gr0nP2W7jBes"
      },
      "outputs": [],
      "source": [
        "model = leNet_model()\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsNrqi8GjI0p",
        "outputId": "be6f0abe-de92-41ed-eeb4-ecd4e4cb3fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 1s/step - accuracy: 0.2088 - loss: 2.9393 - val_accuracy: 0.8415 - val_loss: 0.4825\n",
            "Epoch 2/20\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 1s/step - accuracy: 0.7456 - loss: 0.8491 - val_accuracy: 0.9342 - val_loss: 0.1987\n",
            "Epoch 3/20\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 1s/step - accuracy: 0.8526 - loss: 0.4854 - val_accuracy: 0.9599 - val_loss: 0.1272\n",
            "Epoch 4/20\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 1s/step - accuracy: 0.8931 - loss: 0.3477 - val_accuracy: 0.9800 - val_loss: 0.0774\n",
            "Epoch 5/20\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 1s/step - accuracy: 0.9120 - loss: 0.2786 - val_accuracy: 0.9785 - val_loss: 0.0783\n",
            "Epoch 6/20\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 990ms/step - accuracy: 0.9243 - loss: 0.2394 - val_accuracy: 0.9773 - val_loss: 0.0769\n",
            "Epoch 7/20\n",
            "\u001b[1m224/348\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 965ms/step - accuracy: 0.9351 - loss: 0.2108"
          ]
        }
      ],
      "source": [
        " history = model.fit(datagen.flow(X_train, y_train, batch_size=100), epochs=20, validation_data=(X_val, y_val), shuffle=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EFL4nJxjuTY"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['training', 'validation'])\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJvSdcICkzHn"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['training', 'validation'])\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1-lc-Rpk_mf"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(X_test, y_test, verbose = 0)\n",
        "print('Test Score:', score[0])\n",
        "print('Test Accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaG2LXhclTf6"
      },
      "outputs": [],
      "source": [
        "#predict internet number\n",
        "import requests\n",
        "from PIL import Image\n",
        "url = 'https://c8.alamy.com/comp/G667W0/road-sign-speed-limit-30-kmh-zone-passau-bavaria-germany-G667W0.jpg'\n",
        "r = requests.get(url, stream=True)\n",
        "img = Image.open(r.raw)\n",
        "plt.imshow(img, cmap=plt.get_cmap('gray'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvf-z2vVqeDY"
      },
      "outputs": [],
      "source": [
        "img = np.asarray(img)\n",
        "img = cv2.resize(img, (32, 32))\n",
        "img = preprocessing(img)\n",
        "plt.imshow(img, cmap = plt.get_cmap('gray'))\n",
        "print(img.shape)\n",
        "img = img.reshape(1, 32, 32, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duoSkJceqnSl"
      },
      "outputs": [],
      "source": [
        "# Predict probabilities for each class\n",
        "predicted_probabilities = model.predict(img)\n",
        "\n",
        "# Find the class with the highest probability\n",
        "predicted_class = int(np.argmax(predicted_probabilities))\n",
        "\n",
        "print(\"predicted class:\", predicted_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-0AuEJFqxAp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}